{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Implementing a custom analysis block in Lightwood\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "As you might already know, Lightwood is designed to be a flexible machine learning (ML) library that is able to abstract and automate the entire ML pipeline. Crucially, it is also designed to be extended or modified very easily according to your needs, essentially offering the entire spectrum between fully automated AutoML and a lightweight wrapper for customized ML pipelines.\n",
    "\n",
    "As such, we can identify several different customizable \"phases\" in the process. The relevant phase for this tutorial is the \"analysis\" that comes after a predictor has been trained. The goal of this phase is to generate useful insights, like accuracy metrics, confusion matrices, feature importance, etc. These particular examples are all included in the core analysis procedure that Lightwood executes.\n",
    "\n",
    "However, the analysis procedure is structured into a sequential execution of \"analysis blocks\". Each analysis block should generate a well-defined set of insights, as well as handling any actions regarding these at inference time.\n",
    "\n",
    "As an example, one of the core blocks is the Inductive Conformal Prediction (`ICP`) block, which handles the confidence estimation of all Lightwood predictors. The logic within can be complex at times, but thanks to the block abstraction we can deal with it in a structured manner. As this `ICP` block is used when generating predictions, it implements the two main methods that the `BaseAnalysisBlock` class specifies: `.analyze()` to setup everything that is needed, and `.explain()` to actually estimate the confidence in any given prediction.\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this tutorial, we will go through the steps required to implement your own analysis blocks to customize the insights of any Lightwood predictor!\n",
    "\n",
    "In particular, we will implement a \"model correlation heatmap\" block: we want to compare the predictions of all mixers inside a `BestOf` ensemble object, to understand how they might differ in their overall behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "import lightwood\n",
    "lightwood.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: figuring out what we need\n",
    "\n",
    "When designing an analysis block, an important choice needs to be made: will this block operate when calling the predictor? Or is it only going to describe its performance once in the held-out validation dataset?\n",
    "\n",
    "Being in the former case means we need to implement both `.analyze()` and `.explain()` methods, while the latter case only needs an `.analyze()` method. Our `ModelCorrelationHeatmap` belongs to this second category.\n",
    "\n",
    "Let's start the implementation by inheriting from `BaseAnalysisBlock`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.analysis import BaseAnalysisBlock\n",
    "\n",
    "class ModelCorrelationHeatmap(BaseAnalysisBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def analyze(self, info: Dict[str, object], **kwargs) -> Dict[str, object]:\n",
    "        return info\n",
    "\n",
    "    def explain(self,\n",
    "                row_insights: pd.DataFrame,\n",
    "                global_insights: Dict[str, object], **kwargs) -> Tuple[pd.DataFrame, Dict[str, object]]:\n",
    "        \n",
    "        return row_insights, global_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ModelCorrelationHeatmap at 0x7fa85c015970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelCorrelationHeatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, our newly created analysis block doesn't do much, apart from returning the `info` and insights (`row_insights` and `global_insights`) exactly as it received them from the previous block.\n",
    "\n",
    "As previously discussed, we only need to implement a procedure that runs post-training, no action is required at inference time. This means we can use the default `.explain()` behavior in the parent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCorrelationHeatmap(BaseAnalysisBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def analyze(self, info: Dict[str, object], **kwargs) -> Dict[str, object]:\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implementing the custom analysis block\n",
    "\n",
    "Okay, now for the fun bit: we have to implement a correlation heatmap between the predictions of all mixers inside a `BestOf` ensemble. This is currently the only ensemble implemented in Lightwood, but it is a good idea to explicitly check that the type of the ensemble is what we expect.\n",
    "\n",
    "A natural question to ask at this point is: what information do we have to implement the procedure? You'll note that, apart from the `info` dictionary, we receive a `kwargs` dictionary. You can check out the full documentation for more details, but the keys (and respective value types) exposed in this object by default are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        'predictor': 'lightwood.ensemble.BaseEnsemble',\n",
    "        'target': 'str',\n",
    "        'input_cols': 'list',\n",
    "        'dtype_dict': 'dict',\n",
    "        'normal_predictions': 'pd.DataFrame',\n",
    "        'data': 'pd.DataFrame',\n",
    "        'train_data': 'lightwood.data.encoded_ds.EncodedDs',\n",
    "        'encoded_val_data': 'lightwood.data.encoded_ds.EncodedDs',\n",
    "        'is_classification': 'bool',\n",
    "        'is_numerical': 'bool',\n",
    "        'is_multi_ts': 'bool',\n",
    "        'stats_info': 'lightwood.api.types.StatisticalAnalysis',\n",
    "        'ts_cfg': 'lightwood.api.types.TimeseriesSettings',\n",
    "        'accuracy_functions': 'list',\n",
    "        'has_pretrained_text_enc': 'bool'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there is lots to work with, but for this example we will focus on using:\n",
    "\n",
    "1. The `predictor` ensemble\n",
    "2. The `encoded_val_data` to generate predictions for each mixer inside the ensemble\n",
    "\n",
    "And the insight we're want to produce is a matrix that compares the output of all mixers and computes the correlation between them.\n",
    "\n",
    "Let's implement the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from lightwood.ensemble import BestOf\n",
    "from lightwood.analysis import BaseAnalysisBlock\n",
    "\n",
    "\n",
    "class ModelCorrelationHeatmap(BaseAnalysisBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def analyze(self, info: Dict[str, object], **kwargs) -> Dict[str, object]:\n",
    "        ns = SimpleNamespace(**kwargs)\n",
    "        \n",
    "        # only triggered with the right type of ensemble\n",
    "        if isinstance(ns.predictor, BestOf):\n",
    "            \n",
    "            # store prediction from every mixer\n",
    "            all_predictions = []\n",
    "\n",
    "            for mixer in ns.predictor.mixers:\n",
    "                predictions = mixer(ns.encoded_val_data).values  # retrieve np.ndarray from the returned pd.DataFrame\n",
    "                all_predictions.append(predictions.flatten().astype(int))  # flatten and cast labels to int\n",
    "                \n",
    "            # calculate correlation matrix\n",
    "            corrs = np.corrcoef(np.array(all_predictions))\n",
    "            \n",
    "            # save inside `info` object\n",
    "            info['mixer_correlation'] = corrs\n",
    "        \n",
    "        return info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `SimpleNamespace` for dot notation accessors.\n",
    "\n",
    "The procedure above is fairly straightforward, as we leverage numpy's `corrcoef()` function to generate the matrix. \n",
    "\n",
    "Finally, it is very important to add the output to `info` so that it is saved inside the actual predictor object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exposing the block to Lightwood\n",
    "\n",
    "\n",
    "To use this in an arbitrary script, we need to add the above class (and all necessary imports) to a `.py` file inside one of the following directories:\n",
    "\n",
    "* `~/lightwood_modules` (where `~` is your home directory, e.g. `/Users/username/` for macOS and `/home/username/` for linux\n",
    "* `/etc/lightwood_modules`\n",
    "\n",
    "Lightwood will scan these directories and import any class so that they can be found and used by the `JsonAI` code generating module.\n",
    "\n",
    "**To continue, please save the code cell above as `model_correlation.py` in one of the indicated directories.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Final test run\n",
    "\n",
    "Ok! Everything looks set to try out our custom block. Let's generate a predictor for [this](https://github.com/mindsdb/lightwood/blob/stable/tests/data/hdi.csv) sample dataset, and see whether our new insights are any good.\n",
    "\n",
    "First, it is important to add our `ModelCorrelationHeatmap` to the `analysis_blocks` attribute of the Json AI object that will generate your predictor code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightwood-53131:Dropping features: []\n",
      "INFO:lightwood-53131:Analyzing a sample of 222\n",
      "INFO:lightwood-53131:from a total population of 225, this is equivalent to 98.7% of your data.\n",
      "INFO:lightwood-53131:Using 15 processes to deduct types.\n",
      "INFO:lightwood-53131:Infering type for: Population\n",
      "INFO:lightwood-53131:Infering type for: Area (sq. mi.)\n",
      "INFO:lightwood-53131:Infering type for: Pop. Density \n",
      "INFO:lightwood-53131:Infering type for: GDP ($ per capita)\n",
      "INFO:lightwood-53131:Infering type for: Literacy (%)\n",
      "INFO:lightwood-53131:Infering type for: Infant mortality \n",
      "INFO:lightwood-53131:Infering type for: Development Index\n",
      "INFO:lightwood-53131:Column Area (sq. mi.) has data type integer\n",
      "INFO:lightwood-53131:Column Population has data type integer\n",
      "INFO:lightwood-53131:Column Development Index has data type categorical\n",
      "INFO:lightwood-53131:Column Literacy (%) has data type float\n",
      "INFO:lightwood-53131:Column GDP ($ per capita) has data type integer\n",
      "INFO:lightwood-53131:Column Infant mortality  has data type float\n",
      "INFO:lightwood-53131:Column Pop. Density  has data type float\n",
      "INFO:lightwood-53131:Starting statistical analysis\n",
      "INFO:lightwood-53131:Finished statistical analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_correlation.py\n",
      "model_correlation\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition, json_ai_from_problem\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mindsdb/lightwood/stable/tests/data/hdi.csv')\n",
    "\n",
    "# define the predictive task\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'Development Index',         # column you want to predict\n",
    "    'time_aim': 100,\n",
    "})\n",
    "\n",
    "# generate the Json AI intermediate representation from the data and its corresponding settings\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# add the custom list of analysis blocks; in this case, composed of a single block\n",
    "json_ai.analysis_blocks = [{\n",
    "    'module': 'model_correlation.ModelCorrelationHeatmap',\n",
    "    'args': {}\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the respective Json AI key just to confirm our newly added analysis block is in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'module': 'model_correlation.ModelCorrelationHeatmap', 'args': {}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ai.analysis_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a predictor from this Json AI, and subsequently train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightwood-53131:Dropping features: []\n",
      "INFO:lightwood-53131:Performing statistical analysis on data\n",
      "INFO:lightwood-53131:Starting statistical analysis\n",
      "INFO:lightwood-53131:Finished statistical analysis\n",
      "INFO:lightwood-53131:Cleaning the data\n",
      "INFO:lightwood-53131:Splitting the data into train/test\n",
      "WARNING:lightwood-53131:Cannot stratify, got subsets of length: [25, 24, 23, 22, 22, 22, 22, 22, 22, 21] | Splitting without stratification\n",
      "INFO:lightwood-53131:Preparing the encoders\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 1\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 2\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 3\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 4\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 5\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 6\n",
      "INFO:lightwood-53131:Encoder prepping dict length of: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_correlation.py\n",
      "model_correlation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightwood-53131:Done running for: Development Index\n",
      "INFO:lightwood-53131:Done running for: Population\n",
      "INFO:lightwood-53131:Done running for: Area (sq. mi.)\n",
      "INFO:lightwood-53131:Done running for: Pop. Density \n",
      "INFO:lightwood-53131:Done running for: GDP ($ per capita)\n",
      "INFO:lightwood-53131:Done running for: Literacy (%)\n",
      "INFO:lightwood-53131:Done running for: Infant mortality \n",
      "INFO:lightwood-53131:Featurizing the data\n",
      "INFO:lightwood-53131:Training the mixers\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "WARNING:lightwood-53131:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\n",
      "INFO:lightwood-53131:Loss of 2.1644320487976074 with learning rate 0.0001\n",
      "INFO:lightwood-53131:Loss of 2.4373621940612793 with learning rate 0.00014\n",
      "INFO:lightwood-53131:Found learning rate of: 0.0001\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "DEBUG:lightwood-53131:Loss @ epoch 1: 1.6043835878372192\n",
      "DEBUG:lightwood-53131:Loss @ epoch 2: 1.614564061164856\n",
      "DEBUG:lightwood-53131:Loss @ epoch 3: 1.6116881370544434\n",
      "DEBUG:lightwood-53131:Loss @ epoch 4: 1.6085857152938843\n",
      "DEBUG:lightwood-53131:Loss @ epoch 5: 1.5999916791915894\n",
      "DEBUG:lightwood-53131:Loss @ epoch 6: 1.5959053039550781\n",
      "DEBUG:lightwood-53131:Loss @ epoch 7: 1.5914497375488281\n",
      "DEBUG:lightwood-53131:Loss @ epoch 8: 1.586897850036621\n",
      "DEBUG:lightwood-53131:Loss @ epoch 9: 1.582642912864685\n",
      "DEBUG:lightwood-53131:Loss @ epoch 10: 1.5786747932434082\n",
      "DEBUG:lightwood-53131:Loss @ epoch 11: 1.5690934658050537\n",
      "DEBUG:lightwood-53131:Loss @ epoch 12: 1.5649737119674683\n",
      "DEBUG:lightwood-53131:Loss @ epoch 13: 1.5617222785949707\n",
      "DEBUG:lightwood-53131:Loss @ epoch 14: 1.5580050945281982\n",
      "DEBUG:lightwood-53131:Loss @ epoch 15: 1.55539071559906\n",
      "DEBUG:lightwood-53131:Loss @ epoch 16: 1.5526844263076782\n",
      "DEBUG:lightwood-53131:Loss @ epoch 17: 1.5471524000167847\n",
      "DEBUG:lightwood-53131:Loss @ epoch 18: 1.5454663038253784\n",
      "DEBUG:lightwood-53131:Loss @ epoch 19: 1.5436923503875732\n",
      "DEBUG:lightwood-53131:Loss @ epoch 20: 1.5420359373092651\n",
      "DEBUG:lightwood-53131:Loss @ epoch 21: 1.5407888889312744\n",
      "DEBUG:lightwood-53131:Loss @ epoch 22: 1.5401763916015625\n",
      "DEBUG:lightwood-53131:Loss @ epoch 23: 1.5390430688858032\n",
      "DEBUG:lightwood-53131:Loss @ epoch 24: 1.53862726688385\n",
      "DEBUG:lightwood-53131:Loss @ epoch 25: 1.5379230976104736\n",
      "DEBUG:lightwood-53131:Loss @ epoch 26: 1.5374646186828613\n",
      "DEBUG:lightwood-53131:Loss @ epoch 27: 1.5376394987106323\n",
      "DEBUG:lightwood-53131:Loss @ epoch 28: 1.5372562408447266\n",
      "DEBUG:lightwood-53131:Loss @ epoch 29: 1.537568211555481\n",
      "DEBUG:lightwood-53131:Loss @ epoch 1: 1.5716121435165404\n",
      "DEBUG:lightwood-53131:Loss @ epoch 2: 1.5647767543792725\n",
      "DEBUG:lightwood-53131:Loss @ epoch 3: 1.5728715658187866\n",
      "DEBUG:lightwood-53131:Loss @ epoch 4: 1.5768787622451783\n",
      "DEBUG:lightwood-53131:Loss @ epoch 5: 1.5729807138442993\n",
      "DEBUG:lightwood-53131:Loss @ epoch 6: 1.56294903755188\n",
      "DEBUG:lightwood-53131:Loss @ epoch 7: 1.5892131805419922\n",
      "INFO:lightwood-53131:Started fitting LGBM model\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "INFO:lightwood-53131:A single GBM iteration takes 0.1 seconds\n",
      "INFO:lightwood-53131:Training GBM (<module 'lightgbm' from '/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/__init__.py'>) with 176 iterations given 22 seconds constraint\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "INFO:lightwood-53131:Lightgbm model contains 880 weak estimators\n",
      "INFO:lightwood-53131:Updating lightgbm model with 10.5 iterations\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "INFO:lightwood-53131:Model now has a total of 880 weak estimators\n",
      "WARNING:lightwood-53131:Exception: Unspported categorical type for regression when training mixer: <lightwood.mixer.regression.Regression object at 0x7fa84c42f640>\n",
      "INFO:lightwood-53131:Ensembling the mixer\n",
      "INFO:lightwood-53131:Mixer: Neural got accuracy: 0.2916666666666667\n",
      "INFO:lightwood-53131:Mixer: LightGBM got accuracy: 1.0\n",
      "INFO:lightwood-53131:Picked best mixer: LightGBM\n",
      "INFO:lightwood-53131:Analyzing the ensemble of mixers\n",
      "INFO:lightwood-53131:Adjustment on validation requested.\n",
      "INFO:lightwood-53131:Updating the mixers\n",
      "DEBUG:lightwood-53131:Loss @ epoch 1: 1.532525897026062\n",
      "DEBUG:lightwood-53131:Loss @ epoch 2: 1.6230510274569194\n",
      "DEBUG:lightwood-53131:Loss @ epoch 3: 1.529026726881663\n",
      "DEBUG:lightwood-53131:Loss @ epoch 4: 1.4609563549359639\n",
      "DEBUG:lightwood-53131:Loss @ epoch 5: 1.6120732029279072\n",
      "INFO:lightwood-53131:Updating lightgbm model with 10.5 iterations\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "INFO:lightwood-53131:Model now has a total of 880 weak estimators\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "\n",
    "predictor.learn(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visualize the mixer correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mc = predictor.runtime_analyzer['mixer_correlation']  # newly produced insight\n",
    "\n",
    "mixer_names = [c.__class__.__name__ for c in predictor.ensemble.mixers]\n",
    "\n",
    "# plotting code\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(mc, cmap='seismic')\n",
    "\n",
    "# set ticks\n",
    "ax.set_xticks(np.arange(mc.shape[0]))\n",
    "ax.set_yticks(np.arange(mc.shape[1]))\n",
    "\n",
    "# set tick labels\n",
    "ax.set_xticklabels(mixer_names)\n",
    "ax.set_yticklabels(mixer_names)\n",
    "\n",
    "# show cell values\n",
    "for i in range(len(mixer_names)):\n",
    "    for j in range(len(mixer_names)):\n",
    "        text = ax.text(j, i, round(mc[i, j], 3), ha=\"center\", va=\"center\", color=\"w\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We've just added an additional piece of insight regarding the predictor that Lightwood came up with for the task of predicting the Human Development Index of any given country.\n",
    "\n",
    "What this matrix is telling us is whether the predictions of both mixers stored in the ensemble -- Neural and LightGBM -- have a high correlation or not.\n",
    "\n",
    "This is, of course, a very simple example, but it shows the convenience of such an abstraction within the broader pipeline that Lightwood automates.\n",
    "\n",
    "For more complex examples, you can check out any of the three core analysis blocks that we use:\n",
    "\n",
    "* `lightwood.analysis.nc.calibrate.ICP`\n",
    "* `lightwood.analysis.helpers.acc_stats.AccStats`\n",
    "* `lightwood.analysis.helpers.feature_importance.GlobalFeatureImportance`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdb",
   "language": "python",
   "name": "mdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
